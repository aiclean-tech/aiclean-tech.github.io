"use strict";(self.webpackChunkaiclean=self.webpackChunkaiclean||[]).push([[725],{4126:(e,t,r)=>{r.r(t),r.d(t,{default:()=>u});var n=r(5043);const i={videoBox:"CompD_videoBox__1B8p1",videoContent:"CompD_videoContent__SlJSJ",title:"CompD_title__s+LnR",dateButton:"CompD_dateButton__t9S8M",subtitle:"CompD_subtitle__+9Ubw",articleContainer:"CompD_articleContainer__2DRrj",abstract:"CompD_abstract__kBJ6f",author:"CompD_author__A21oG",viewPaperButton:"CompD_viewPaperButton__w4KND",navigationButtons:"CompD_navigationButtons__58LJe",navButton:"CompD_navButton__tU4tK",descriptionImage:"CompD_descriptionImage__nrN7o",descriptionImage2:"CompD_descriptionImage2__hENTd"};var s=r(6446),o=r(5865);var a=r(3169);const c=r.p+"static/media/CompD-table1.8c65c7c70e2274dc99fa.png",l=r.p+"static/media/CompD-table2.1cee19d2a81641c25140.png";var d=r(6213),h=r(579);const u=()=>{const[e,t]=(0,n.useState)(null),[r,u]=(0,n.useState)(null),[g,p]=(0,n.useState)(null),[m,f]=(0,n.useState)(null),[v,x]=(0,n.useState)(null),[j,D]=(0,n.useState)(null),[y,b]=(0,n.useState)(null),[w,C]=(0,n.useState)(null),[_,T]=(0,n.useState)(null),[N,A]=(0,n.useState)(null);return(0,h.jsxs)("div",{className:i.pageContainer,children:[(0,h.jsx)(s.A,{className:i.videoBox,children:(0,h.jsx)(s.A,{className:i.videoContent,children:(0,h.jsx)(o.A,{variant:"h3",className:i.title,children:"Detecting and Repairing Deviated Outputs of Compressed Models"})})}),(0,h.jsxs)(s.A,{className:i.articleContainer,children:[(0,h.jsxs)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:["To date, it is widely acknowledged that model compression methods have been successfully deployed to reduce computations, decrease power demands, and thus enable the deployment of DNNs on low-power devices. Furthermore, it is shown that compressed models can often exhibit overall high test accuracy compared to the original DNN models. ",(0,h.jsx)("br",{}),"Nevertheless, our observation shows that the original model Mo and its compressed version Mc (e.g., via pruning), though they may both exhibit high test accuracy, can have deviated prediction outputs on the same input, as illustrated in following figure. We name such inputs as ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"}),". We propose ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})}),", the first testing and repairing framework to detect prediction deviations between original models and their compressed counterparts.",(0,h.jsx)("img",{src:a,alt:"Description",className:i.descriptionImage}),"We demonstrate capability of ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})})," using two representative compression schemes: quantization and pruning. Three common DNN models, VGG11, ResNet18, and DenseNet121, trained on CIFAR-10, are selected as our tested models. All the compressed models exhibit similar or even higher accuracy than their original counterparts. However, ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})})," still detects a great number of ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," with 5000 seed inputs.",(0,h.jsx)("img",{src:c,alt:"Description",className:i.descriptionImage2}),"With the ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," discovered by ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})}),", we can repair Mc. We first collect proper set of ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," for repairing. Then we utilize this set of inputs to finetune Mc to improve its robustness against ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"}),".",(0,h.jsx)("img",{src:l,alt:"Description",className:i.descriptionImage2})]}),(0,h.jsx)(o.A,{variant:"h3",gutterBottom:!0,className:i.abstract,children:(0,h.jsx)("strong",{children:"Demo:"})}),(0,h.jsx)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:"We use pruning on VGG11 for demonstraction. Let's first test the accuracy of the original model and the pruned model."}),(0,h.jsx)("button",{onClick:async()=>{try{const e=await(async()=>{try{return(await(0,d.A)({url:"http://143.89.126.47:8825/test_ori",method:"GET"})).data.acc}catch(e){throw console.error("Error fetching acc:",e),e}})();t(e),u(null)}catch(e){u("Failed to fetch acc. Please try again.")}},children:"Calculate Accuracy of Original Model"}),null!==e&&(0,h.jsxs)("div",{children:["Acc Value: ",e]}),r&&(0,h.jsx)("div",{style:{color:"red"},children:r}),(0,h.jsx)("button",{onClick:async()=>{try{const e=await(async()=>{try{return(await(0,d.A)({url:"http://143.89.126.47:8825/test_comp",method:"GET"})).data.acc}catch(e){throw console.error("Error fetching acc:",e),e}})();p(e),f(null)}catch(e){f("Failed to fetch acc. Please try again.")}},children:"Calculate Accuracy of Pruned Model"}),null!==g&&(0,h.jsxs)("div",{children:["Acc Value: ",g]}),m&&(0,h.jsx)("div",{style:{color:"red"},children:r}),(0,h.jsxs)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:["The difference of the accuracy between the pruned model and its original version is small. However, ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})})," can still find many ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"}),". Let's just use 50 inputs from original testset as seeds for searching ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"}),', so the process will complete soon. (Click on the button below. Once the process complete, the "Search Status" will turn to complete)']}),(0,h.jsx)("button",{onClick:async()=>{try{const e=await(async()=>{try{return(await(0,d.A)({url:"http://143.89.126.47:8825/search",method:"GET"})).data.result}catch(e){throw console.error("Error fetching result:",e),e}})();x(e),D(null)}catch(e){D("Failed to fetch acc. Please try again.")}},children:"Search for the DTI"}),null!==v&&(0,h.jsx)("div",{children:"Search Status: Complete"}),null==v&&(0,h.jsx)("div",{children:"Search Status: Not complete yet"}),j&&(0,h.jsx)("div",{style:{color:"red"},children:j}),(0,h.jsxs)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:["Let's test out how many ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," are effective on the pruned model."]}),(0,h.jsx)("button",{onClick:async()=>{try{const e=await(async()=>{try{return(await(0,d.A)({url:"http://143.89.126.47:8825/testcomp",method:"GET"})).data.result}catch(e){throw console.error("Error fetching result:",e),e}})();b(e),C(null)}catch(e){C("Failed to fetch acc. Please try again.")}},children:"Test Effect of DTI on Pruned Model"}),null!==y&&(0,h.jsxs)("div",{children:["Effective DTI: ",y]}),w&&(0,h.jsx)("div",{style:{color:"red"},children:w}),(0,h.jsxs)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:["All these ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," are effective, which means they can only cause pruned model to make wrong prediction while keeping original model's prediction. In such a short time, we have found out many effective ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"}),". It is noted that, the number of ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," found is proportional to the time spent. ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})})," reveals potential big threats to the compressed model!"]}),(0,h.jsxs)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:["To mitigate this issue, ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})})," repair the compressed model with finetuning. Let's test out how many ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," are still effective on reparied model."]}),(0,h.jsx)("button",{onClick:async()=>{try{const e=await(async()=>{try{return(await(0,d.A)({url:"http://143.89.126.47:8825/testrep",method:"GET"})).data.result}catch(e){throw console.error("Error fetching result:",e),e}})();T(e),A(null)}catch(e){A("Failed to fetch acc. Please try again.")}},children:"Test Effect of DTI on Repaired Model"}),null!==_&&(0,h.jsxs)("div",{children:["Effective DTI: ",_]}),N&&(0,h.jsx)("div",{style:{color:"red"},children:N}),(0,h.jsxs)(o.A,{variant:"h6",gutterBottom:!0,className:i.abstract,children:["Much less ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," are still effective! We need to declare that both these ",(0,h.jsx)("strong",{children:"deviation-triggering (DT) inputs"})," and their corresponding seeds are not in the dataset for finetuning, which shows ",(0,h.jsx)("font",{color:"blue",children:(0,h.jsx)("strong",{children:"CompD"})}),"'s ability of generalization."]})]})]})}},3169:(e,t,r)=>{e.exports=r.p+"static/media/CompD.bd1c019aef176fd57a7f.png"}}]);
//# sourceMappingURL=725.f27ea2dc.chunk.js.map